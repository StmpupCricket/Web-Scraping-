name: Daily Job Scraping

on:
  schedule:
    # Runs daily at 8 AM UTC (3 AM Colombia time)
    - cron: '0 8 * * *'
  workflow_dispatch:  # Allows manual trigger
  push:
    branches: [ main ]

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium webdriver-manager pandas
        
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
        
    - name: Run scraping script
      env:
        RUN_ON_GITHUB: 'true'
      run: |
        python github_scraper.py
        
    - name: Check if CSV files exist
      run: |
        echo "Checking for CSV files..."
        ls -la datos/ || echo "datos directory doesn't exist"
        find . -name "*.csv" -type f || echo "No CSV files found"
        
    - name: Commit and push data
      if: success()
      run: |
        # Check if there are any CSV files to commit
        if ls datos/*.csv 1> /dev/null 2>&1; then
          echo "CSV files found, committing..."
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add datos/*.csv
          git commit -m "Update job data $(date +'%Y-%m-%d %H:%M:%S')"
          git push origin HEAD:main
        else
          echo "No CSV files to commit"
        fi
